"""
Critic Agent - Wissenschaftlich basierte Validierung von Injects.

Verantwortlich f√ºr:
- Evidenzbasierte Validierung mit quantifizierbaren Metriken
- Statistische Signifikanz-Tests
- Multi-Layer Validierung (symbolisch ‚Üí LLM)
- Compliance-Validierung mit variablen Standards
- Causal Validity (MITRE ATT&CK Graph Konformit√§t)
- Refine-Loop mit wissenschaftlichen Verbesserungsvorschl√§gen

Wissenschaftliche Methoden:
- Quantifizierbare Metriken (0.0-1.0 Scores)
- Konfidenz-Intervalle (95% CI)
- Statistische Signifikanz-Tests (p-value)
- Reproduzierbare Validierung
- Evidence-based Entscheidungen
"""

from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from state_models import Inject, ValidationResult, CrisisPhase
from workflows.fsm import CrisisFSM
from agents.critic_metrics import ScientificValidator, ValidationMetrics
from utils.json_encoder import DateTimeEncoder
import os
from dotenv import load_dotenv
from datetime import datetime
import json
from pathlib import Path

# Optional: Compliance-Framework Import (f√ºr variable Compliance-Standards)
COMPLIANCE_AVAILABLE = False
ComplianceStandard = None
DORAComplianceFramework = None
NISTComplianceFramework = None
ISO27001ComplianceFramework = None

try:
    import sys
    import importlib.util
    from pathlib import Path
    # Ensure parent directory is in path
    parent_dir = Path(__file__).parent.parent
    if str(parent_dir) not in sys.path:
        sys.path.insert(0, str(parent_dir))
    
    # Handle case-insensitive filesystem (macOS): Import Compliance as compliance
    # Use importlib to load Compliance directory as 'compliance' module
    compliance_dir = parent_dir / "Compliance"
    if compliance_dir.exists() and compliance_dir.is_dir():
        # Load the module using importlib
        spec = importlib.util.spec_from_file_location(
            "compliance", 
            compliance_dir / "__init__.py",
            submodule_search_locations=[str(compliance_dir)]
        )
        if spec and spec.loader:
            compliance_module = importlib.util.module_from_spec(spec)
            sys.modules["compliance"] = compliance_module
            spec.loader.exec_module(compliance_module)
            
            # Now import from the loaded module
            from compliance.base import ComplianceStandard
            from compliance.dora import DORAComplianceFramework
            from compliance.nist import NISTComplianceFramework
            from compliance.iso27001 import ISO27001ComplianceFramework
            COMPLIANCE_AVAILABLE = True
        else:
            COMPLIANCE_AVAILABLE = False
    else:
        # Fallback: try normal import (in case directory is already lowercase)
        from compliance.base import ComplianceStandard
        from compliance.dora import DORAComplianceFramework
        from compliance.nist import NISTComplianceFramework
        from compliance.iso27001 import ISO27001ComplianceFramework
        COMPLIANCE_AVAILABLE = True
except (ImportError, ModuleNotFoundError, Exception) as e:
    # Fallback f√ºr R√ºckw√§rtskompatibilit√§t - funktioniert auch ohne compliance Modul
    COMPLIANCE_AVAILABLE = False

load_dotenv()


class CriticAgent:
    """
    Critic Agent f√ºr Inject-Validierung.
    
    Simuliert Compliance- und Tech-Experten zur Validierung von Injects.
    F√ºhrt Reflect-Refine Loop durch, um Injects zu verbessern.
    """
    
    def __init__(
        self,
        model_name: str = "gpt-4o",
        temperature: float = 0.3,
        compliance_standards: Optional[List[ComplianceStandard]] = None
    ):
        """
        Initialisiert den Critic Agent.
        
        Args:
            model_name: OpenAI Modell-Name
            temperature: Temperature (niedrig f√ºr konsistente Validierung)
            compliance_standards: Liste von Compliance-Standards (Standard: [DORA])
        """
        self.llm = ChatOpenAI(
            model=model_name,
            temperature=temperature,
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        # Initialisiere Compliance-Frameworks
        self.compliance_frameworks: Dict[str, Any] = {}
        if COMPLIANCE_AVAILABLE and ComplianceStandard is not None:
            if compliance_standards is None:
                compliance_standards = [ComplianceStandard.DORA]
            
            for standard in compliance_standards:
                if standard == ComplianceStandard.DORA and DORAComplianceFramework is not None:
                    self.compliance_frameworks[standard] = DORAComplianceFramework()
                elif standard == ComplianceStandard.NIST and NISTComplianceFramework is not None:
                    self.compliance_frameworks[standard] = NISTComplianceFramework()
                elif standard == ComplianceStandard.ISO27001 and ISO27001ComplianceFramework is not None:
                    self.compliance_frameworks[standard] = ISO27001ComplianceFramework()
        
        # Initialisiere wissenschaftlichen Validator
        self.scientific_validator = ScientificValidator()
        
        # Metriken-Historie f√ºr statistische Analysen
        self.validation_history: List[Dict[str, float]] = []
    
    def validate_inject(
        self,
        inject: Inject,
        previous_injects: List[Inject],
        current_phase: CrisisPhase,
        system_state: Dict[str, Any],
        mode: str = 'thesis',
        compliance_standards: Optional[List[ComplianceStandard]] = None
    ) -> ValidationResult:
        """
        Validiert einen Inject mit mehrschichtiger Validierung.
        
        Strategie: Fr√ºhe symbolische Validierung VOR LLM-Call, um API-Costs zu sparen.
        
        Args:
            inject: Zu validierender Inject
            previous_injects: Liste vorheriger Injects f√ºr Konsistenz
            current_phase: Aktuelle Phase
            system_state: Aktueller Systemzustand
            mode: 'legacy' = Skip Validation (simuliert altes System), 'thesis' = Full Validation (Default)
        
        Returns:
            ValidationResult mit Validierungs-Ergebnissen
        """
        # LEGACY MODE: Skip Validation komplett (simuliert altes System ohne Logic Guard)
        if mode == 'legacy':
            print(f"[Critic] Legacy Mode: Skipping validation for {inject.inject_id}")
            return ValidationResult(
                is_valid=True,
                logical_consistency=True,
                dora_compliance=True,
                causal_validity=True,
                errors=[],
                warnings=[]
            )
        
        print(f"[Critic] Validiere Inject {inject.inject_id}")
        print(f"   Phase: {current_phase.value} ‚Üí {inject.phase.value}")
        print(f"   Assets: {inject.technical_metadata.affected_assets}")
        print(f"   MITRE: {inject.technical_metadata.mitre_id}")
        
        errors = []
        warnings = []
        
        # ===== PHASE 1: SYMBOLISCHE VALIDIERUNG (OHNE LLM-CALL) =====
        # Diese Checks sind schnell und kostenlos - machen sie ZUERST
        
        print(f"üîß [Critic] Phase 1: Symbolische Validierung (ohne LLM-Call)")
        
        # 1.1 Pydantic-Validierung (automatisch)
        try:
            # Inject ist bereits ein Pydantic-Model, Validierung erfolgt automatisch
            pydantic_valid = True
            print(f"   ‚úÖ Pydantic-Validierung: OK")
        except Exception as e:
            print(f"   ‚ùå Pydantic-Validierung fehlgeschlagen: {e}")
            error_msg = f"Schema-Validierung fehlgeschlagen: {e}"
            # Logge auch Pydantic-Fehler f√ºr Audit
            formatted_system_state_str = self._format_system_state(system_state)
            self._log_critic_decision(
                inject_id=inject.inject_id,
                inject=inject,
                system_state=system_state,
                previous_injects=previous_injects,
                current_phase=current_phase,
                llm_validation={"logical_consistency": False, "causal_validity": False, "regulatory_compliance": True, "_raw_llm_output": "Pydantic-Validierungsfehler - kein LLM-Call"},
                final_result={
                    "is_valid": False,
                    "errors": [error_msg],
                    "warnings": [],
                    "pydantic_valid": False,
                    "fsm_valid": True,  # Noch nicht gepr√ºft
                    "state_valid": True,  # Noch nicht gepr√ºft
                    "temporal_valid": True,  # Noch nicht gepr√ºft
                    "logical_consistency": False,
                    "causal_validity": False,
                    "causal_blocking": False
                },
                formatted_system_state_str=formatted_system_state_str
            )
            return ValidationResult(
                is_valid=False,
                logical_consistency=False,
                dora_compliance=True,  # F√ºr R√ºckw√§rtskompatibilit√§t
                causal_validity=False,
                errors=[error_msg]
            )
        
        # 1.2 FSM-Validierung (Phase-√úbergang) - KRITISCH, fr√ºh pr√ºfen
        print(f"   üîß FSM-Validierung...")
        fsm_result = self._validate_phase_transition_detailed(inject, current_phase, previous_injects)
        if not fsm_result["valid"]:
            errors.extend(fsm_result["errors"])
            print(f"   ‚ùå FSM-Versto√ü: {fsm_result['errors']}")
            # FSM-Versto√ü ist kritisch - kein LLM-Call n√∂tig
            # Logge trotzdem f√ºr Audit
            formatted_system_state_str = self._format_system_state(system_state)
            self._log_critic_decision(
                inject_id=inject.inject_id,
                inject=inject,
                system_state=system_state,
                previous_injects=previous_injects,
                current_phase=current_phase,
                llm_validation={"logical_consistency": False, "causal_validity": True, "regulatory_compliance": True, "_raw_llm_output": "FSM-Fehler - kein LLM-Call"},
                final_result={
                    "is_valid": False,
                    "errors": errors,
                    "warnings": fsm_result.get("warnings", []),
                    "pydantic_valid": pydantic_valid,
                    "fsm_valid": False,
                    "state_valid": True,  # Noch nicht gepr√ºft
                    "temporal_valid": True,  # Noch nicht gepr√ºft
                    "logical_consistency": False,
                    "causal_validity": True,
                    "causal_blocking": False
                },
                formatted_system_state_str=formatted_system_state_str
            )
            return ValidationResult(
                is_valid=False,
                logical_consistency=False,
                dora_compliance=True,  # Unbekannt ohne LLM-Call
                causal_validity=True,  # Unbekannt ohne LLM-Call
                errors=errors,
                warnings=fsm_result.get("warnings", [])
            )
        print(f"   ‚úÖ FSM-Validierung: OK")
        
        # 1.3 State-Consistency-Check (Asset-Existenz, Status-Konsistenz)
        print(f"   üîß State-Consistency-Check...")
        state_result = self._validate_state_consistency(inject, system_state, previous_injects)
        if not state_result["valid"]:
            errors.extend(state_result["errors"])
            warnings.extend(state_result.get("warnings", []))
            print(f"   ‚ùå State-Inkonsistenz: {state_result['errors']}")
            # State-Inkonsistenz ist kritisch - kein LLM-Call n√∂tig
            # Logge trotzdem f√ºr Audit
            formatted_system_state_str = self._format_system_state(system_state)
            self._log_critic_decision(
                inject_id=inject.inject_id,
                inject=inject,
                system_state=system_state,
                previous_injects=previous_injects,
                current_phase=current_phase,
                llm_validation={"logical_consistency": False, "causal_validity": True, "regulatory_compliance": True, "_raw_llm_output": "State-Fehler - kein LLM-Call"},
                final_result={
                    "is_valid": False,
                    "errors": errors,
                    "warnings": warnings,
                    "pydantic_valid": pydantic_valid,
                    "fsm_valid": fsm_result["valid"],
                    "state_valid": False,
                    "temporal_valid": True,  # Noch nicht gepr√ºft
                    "logical_consistency": False,
                    "causal_validity": True,
                    "causal_blocking": False
                },
                formatted_system_state_str=formatted_system_state_str
            )
            return ValidationResult(
                is_valid=False,
                logical_consistency=False,
                dora_compliance=True,  # Unbekannt ohne LLM-Call
                causal_validity=True,  # Unbekannt ohne LLM-Call
                errors=errors,
                warnings=warnings
            )
        print(f"   ‚úÖ State-Consistency: OK")
        
        # 1.4 Temporale Konsistenz-Check
        print(f"   üîß Temporale Konsistenz-Check...")
        temporal_result = self._validate_temporal_consistency(inject, previous_injects)
        if not temporal_result["valid"]:
            errors.extend(temporal_result["errors"])
            warnings.extend(temporal_result.get("warnings", []))
            print(f"   ‚ùå Temporale Inkonsistenz: {temporal_result['errors']}")
            # Temporale Inkonsistenz ist kritisch - kein LLM-Call n√∂tig
            # Logge trotzdem f√ºr Audit
            formatted_system_state_str = self._format_system_state(system_state)
            self._log_critic_decision(
                inject_id=inject.inject_id,
                inject=inject,
                system_state=system_state,
                previous_injects=previous_injects,
                current_phase=current_phase,
                llm_validation={"logical_consistency": False, "causal_validity": True, "regulatory_compliance": True, "_raw_llm_output": "Temporaler Fehler - kein LLM-Call"},
                final_result={
                    "is_valid": False,
                    "errors": errors,
                    "warnings": warnings,
                    "pydantic_valid": pydantic_valid,
                    "fsm_valid": fsm_result["valid"],
                    "state_valid": state_result["valid"],
                    "temporal_valid": False,
                    "logical_consistency": False,
                    "causal_validity": True,
                    "causal_blocking": False
                },
                formatted_system_state_str=formatted_system_state_str
            )
            return ValidationResult(
                is_valid=False,
                logical_consistency=False,
                dora_compliance=True,
                causal_validity=True,
                errors=errors,
                warnings=warnings
            )
        print(f"   ‚úÖ Temporale Konsistenz: OK")
        
        warnings.extend(state_result.get("warnings", []))
        warnings.extend(temporal_result.get("warnings", []))
        
        # ===== PHASE 2: LLM-BASIERTE VALIDIERUNG (NUR WENN SYMBOLISCHE CHECKS OK) =====
        # Nur wenn alle symbolischen Checks passiert sind, LLM-Call machen
        print(f"üîß [Critic] Phase 2: LLM-basierte Validierung (alle symbolischen Checks OK)")
        # Speichere formatierten System-State f√ºr Audit-Log
        formatted_system_state_str = self._format_system_state(system_state)
        
        # Compliance-Validierung mit variablen Standards
        compliance_results: Dict[str, Any] = {}
        if COMPLIANCE_AVAILABLE and self.compliance_frameworks:
            if compliance_standards is None:
                compliance_standards = list(self.compliance_frameworks.keys())
            
            for standard in compliance_standards:
                if standard in self.compliance_frameworks:
                    framework = self.compliance_frameworks[standard]
                    try:
                        compliance_result = framework.validate_inject(
                            inject_content=inject.content,
                            inject_phase=current_phase.value,
                            inject_metadata={
                                "mitre_id": inject.technical_metadata.mitre_id,
                                "affected_assets": inject.technical_metadata.affected_assets,
                                "severity": inject.technical_metadata.severity
                            },
                            context={
                                "previous_injects": [
                                    {
                                        "inject_id": inj.inject_id,
                                        "content": inj.content,
                                        "phase": inj.phase.value
                                    }
                                    for inj in previous_injects
                                ]
                            }
                        )
                        if ComplianceStandard is not None:
                            compliance_results[standard.value] = compliance_result
                        else:
                            compliance_results[str(standard)] = compliance_result
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Fehler bei Compliance-Validierung ({standard}): {e}")
        
        llm_validation = self._llm_validate(inject, previous_injects, current_phase, system_state, formatted_system_state_str, compliance_results)
        print(f"   LLM-Ergebnis: logical_consistency={llm_validation['logical_consistency']}, "
              f"regulatory_compliance={llm_validation.get('regulatory_compliance', llm_validation.get('dora_compliance', True))}, "
              f"causal_validity={llm_validation['causal_validity']}")
        
        # Kombiniere alle Ergebnisse
        errors.extend(llm_validation.get("errors", []) or [])
        warnings.extend(llm_validation.get("warnings", []) or [])
        
        # F√ºge Compliance-Warnungen hinzu
        for standard, result in compliance_results.items():
            if not result.is_compliant:
                warnings.append(f"{standard} Compliance: {', '.join(result.requirements_missing)} fehlen")
            if result.warnings:
                warnings.extend([f"{standard}: {w}" for w in result.warnings])
        
        # Finale Validierung
        # Compliance ist weniger kritisch (nur Warnung, kein Blocking-Fehler)
        # Causal Validity: Nur blockieren wenn wirklich unm√∂glich, sonst Warnung
        critical_errors = (
            not pydantic_valid
            or not fsm_result["valid"]
            or not state_result["valid"]
            or not temporal_result["valid"]
            or not llm_validation["logical_consistency"]
        )
        
        # Causal Validity: Nur blockieren wenn wirklich unm√∂glich (z.B. Exfiltration vor Initial Access)
        # Sonst nur Warnung
        causal_blocking = False
        if not llm_validation["causal_validity"]:
            # Pr√ºfe ob es wirklich unm√∂glich ist oder nur ungew√∂hnlich
            mitre_id = inject.technical_metadata.mitre_id or ""
            # Nur wirklich unm√∂gliche Sequenzen blockieren
            impossible_sequences = [
                ("T1041", CrisisPhase.NORMAL_OPERATION),  # Exfiltration vor Initial Access
                ("T1486", CrisisPhase.NORMAL_OPERATION),  # Impact vor Execution
                ("T1041", CrisisPhase.SUSPICIOUS_ACTIVITY),  # Exfiltration vor Initial Access
            ]
            if (mitre_id, current_phase) in impossible_sequences:
                causal_blocking = True
        
        is_valid = not critical_errors and not causal_blocking
        
        # Stelle sicher, dass bei invalider Antwort immer eine Begr√ºndung vorhanden ist
        if not is_valid:
            if not errors:
                # Sammle alle Gr√ºnde warum es nicht valide ist
                reasons = []
                if not pydantic_valid:
                    reasons.append("Pydantic Schema-Validierung fehlgeschlagen")
                if not fsm_result["valid"]:
                    reasons.append("FSM-Phasen-√úbergang nicht erlaubt")
                if not state_result["valid"]:
                    reasons.append("State-Konsistenz-Versto√ü")
                if not temporal_result["valid"]:
                    reasons.append("Temporale Inkonsistenz")
                if not llm_validation["logical_consistency"]:
                    reasons.append("Logische Inkonsistenz")
                if causal_blocking:
                    reasons.append("Kausale Validit√§t nicht gegeben (unm√∂gliche Sequenz)")
                # DORA-Compliance ist nicht mehr blockierend - nur Warnung
                
                if reasons:
                    errors.append(f"Validierung fehlgeschlagen: {', '.join(reasons)}")
                else:
                    errors.append("Validierung fehlgeschlagen, aber keine spezifischen Fehler gefunden.")
        
        print(f"üîç [Critic] Validierung abgeschlossen f√ºr {inject.inject_id}")
        print(f"   Ergebnis: {'‚úÖ VALIDE' if is_valid else '‚ùå NICHT VALIDE'}")
        print(f"   Fehler: {len(errors)}, Warnungen: {len(warnings)}")
        if errors:
            print(f"   Fehler-Details: {errors[:3]}")  # Erste 3 Fehler
        
        # ===== WISSENSCHAFTLICHE METRIKEN-BERECHNUNG =====
        # Berechne quantifizierbare Metriken f√ºr evidenzbasierte Entscheidung
        print(f"üî¨ [Critic] Berechne wissenschaftliche Metriken...")
        
        # 1. Logische Konsistenz-Score
        logical_score = self.scientific_validator.calculate_logical_consistency_score(
            inject=inject,
            previous_injects=previous_injects,
            system_state=system_state
        )
        
        # 2. Kausale Validit√§t-Score
        causal_score = self.scientific_validator.calculate_causal_validity_score(
            inject=inject,
            current_phase=current_phase,
            mitre_id=inject.technical_metadata.mitre_id
        )
        
        # 3. Compliance-Score
        compliance_score = self.scientific_validator.calculate_compliance_score(
            compliance_results=compliance_results
        )
        
        # 4. Temporale Konsistenz-Score
        temporal_score = self.scientific_validator.calculate_temporal_consistency_score(
            inject=inject,
            previous_injects=previous_injects
        ) if previous_injects else 1.0
        
        # 5. Asset-Konsistenz-Score
        asset_score = self.scientific_validator._check_asset_name_consistency(
            inject=inject,
            previous_injects=previous_injects
        )
        
        # Erstelle Metriken-Objekt
        metrics = ValidationMetrics(
            logical_consistency_score=logical_score,
            causal_validity_score=causal_score,
            compliance_score=compliance_score,
            temporal_consistency_score=temporal_score,
            asset_consistency_score=asset_score,
            sample_size=len(previous_injects),
            validation_method="multi_layer"
        )
        
        # Berechne Gesamt-Qualit√§ts-Score
        metrics.overall_quality_score = self.scientific_validator.calculate_overall_quality_score(metrics)
        
        # Berechne Konfidenz-Intervalle
        if len(previous_injects) >= 2:
            metrics.confidence_interval = self.scientific_validator.calculate_confidence_interval(
                score=metrics.overall_quality_score,
                sample_size=len(previous_injects)
            )
        
        # Statistische Signifikanz-Test
        if len(self.validation_history) >= 2:
            historical_scores = [h["overall_quality_score"] for h in self.validation_history[-10:]]
            significance_test = self.scientific_validator.statistical_significance_test(
                current_score=metrics.overall_quality_score,
                historical_scores=historical_scores
            )
            metrics.p_value = significance_test.get("p_value")
            metrics.statistical_significance = significance_test.get("significant", False)
        
        # Speichere Metriken in Historie
        self.validation_history.append({
            "inject_id": inject.inject_id,
            "overall_quality_score": metrics.overall_quality_score,
            "logical_consistency_score": logical_score,
            "causal_validity_score": causal_score,
            "compliance_score": compliance_score
        })
        
        # Begrenze Historie auf letzte 100 Eintr√§ge
        if len(self.validation_history) > 100:
            self.validation_history = self.validation_history[-100:]
        
        print(f"   üìä Metriken: Logical={logical_score:.2f}, Causal={causal_score:.2f}, "
              f"Compliance={compliance_score:.2f}, Overall={metrics.overall_quality_score:.2f}")
        
        # Wissenschaftlich basierte Entscheidung: Verwende Overall Quality Score
        # Anpassung der Validierung basierend auf Metriken
        if metrics.overall_quality_score < self.scientific_validator.thresholds["critical"]:
            # Kritischer Score: Zus√§tzliche Fehler hinzuf√ºgen
            if not any("Qualit√§t" in e for e in errors):
                errors.append(f"Qualit√§ts-Score zu niedrig: {metrics.overall_quality_score:.2f} < {self.scientific_validator.thresholds['critical']:.2f}")
        elif metrics.overall_quality_score < self.scientific_validator.thresholds["warning"]:
            # Warnung bei mittlerem Score
            if not any("Qualit√§t" in w for w in warnings):
                warnings.append(f"Qualit√§ts-Score k√∂nnte verbessert werden: {metrics.overall_quality_score:.2f}")
        
        # Compliance-Ergebnisse zusammenfassen
        overall_compliance = all(
            getattr(result, 'is_compliant', True)
            for result in compliance_results.values()
        ) if compliance_results else True

        # ===== DEEP TRUTH LOGGING =====
        # Logge die vollst√§ndige Entscheidung f√ºr Debugging
        self._log_critic_decision(
            inject_id=inject.inject_id,
            inject=inject,
            system_state=system_state,
            previous_injects=previous_injects,
            current_phase=current_phase,
            llm_validation=llm_validation,
            final_result={
                "is_valid": is_valid,
                "errors": errors,
                "warnings": warnings,
                "pydantic_valid": pydantic_valid,
                "fsm_valid": fsm_result["valid"],
                "state_valid": state_result["valid"],
                "temporal_valid": temporal_result["valid"],
                "logical_consistency": llm_validation["logical_consistency"],
                "causal_validity": llm_validation["causal_validity"],
                "compliance_results": {
                    standard: {
                        "is_compliant": result.is_compliant,
                        "requirements_met": result.requirements_met,
                        "requirements_missing": result.requirements_missing
                    }
                    for standard, result in compliance_results.items()
                } if compliance_results else None,
                "causal_blocking": causal_blocking
            },
            formatted_system_state_str=formatted_system_state_str if 'formatted_system_state_str' in locals() else None
        )

        return ValidationResult(
            is_valid=is_valid,
            logical_consistency=(
                fsm_result["valid"] 
                and state_result["valid"] 
                and temporal_result["valid"]
                and llm_validation["logical_consistency"]
            ),
            dora_compliance=overall_compliance,  # R√ºckw√§rtskompatibilit√§t
            causal_validity=llm_validation["causal_validity"],
            errors=errors,
            warnings=warnings,
            compliance_results={
                standard: result.dict()
                for standard, result in compliance_results.items()
            } if compliance_results else None
        )
    
    def _validate_phase_transition(
        self,
        inject: Inject,
        current_phase: CrisisPhase,
        previous_injects: List[Inject]
    ) -> bool:
        """Validiert, ob der Phase-√úbergang erlaubt ist."""
        # Pr√ºfe ob Phase-√úbergang erlaubt ist
        if inject.phase != current_phase:
            # Phase hat sich ge√§ndert - pr√ºfe ob √úbergang erlaubt
            return CrisisFSM.can_transition(current_phase, inject.phase)
        
        # Phase bleibt gleich - das ist immer erlaubt
        return True
    
    def _validate_phase_transition_detailed(
        self,
        inject: Inject,
        current_phase: CrisisPhase,
        previous_injects: List[Inject]
    ) -> Dict[str, Any]:
        """
        Detaillierte FSM-Validierung mit Fehlermeldungen.
        
        Returns:
            Dict mit "valid" (bool), "errors" (List[str]), "warnings" (List[str])
        """
        errors = []
        warnings = []
        
        # Phase-√úbergang pr√ºfen
        if inject.phase != current_phase:
            if not CrisisFSM.can_transition(current_phase, inject.phase):
                errors.append(
                    f"FSM-Versto√ü: √úbergang von {current_phase.value} zu {inject.phase.value} ist nicht erlaubt. "
                    f"Erlaubte √úberg√§nge von {current_phase.value}: {[p.value for p in CrisisFSM.get_next_phases(current_phase)]}"
                )
                return {"valid": False, "errors": errors, "warnings": warnings}
        
        # Pr√ºfe ob Phase zur Sequenz passt (heuristisch)
        if previous_injects:
            last_phase = previous_injects[-1].phase if previous_injects else current_phase
            # Warnung wenn Phase zur√ºckgeht (au√üer RECOVERY ‚Üí NORMAL_OPERATION)
            if inject.phase.value < last_phase.value and not (
                last_phase == CrisisPhase.RECOVERY and inject.phase == CrisisPhase.NORMAL_OPERATION
            ):
                warnings.append(
                    f"Phase geht zur√ºck: {last_phase.value} ‚Üí {inject.phase.value}. "
                    "Pr√ºfe ob dies logisch ist."
                )
        
        return {"valid": True, "errors": errors, "warnings": warnings}
    
    def _validate_state_consistency(
        self,
        inject: Inject,
        system_state: Dict[str, Any],
        previous_injects: List[Inject]
    ) -> Dict[str, Any]:
        """
        Validiert State-Konsistenz (Asset-Existenz, Status-Konsistenz).
        
        Returns:
            Dict mit "valid" (bool), "errors" (List[str]), "warnings" (List[str])
        """
        errors = []
        warnings = []
        
        # ID-FIRST VALIDATION: Check if asset_id exists in state
        # Only fail if ID is missing, not if description name mismatches
        affected_assets = inject.technical_metadata.affected_assets or []
        
        # Extract known asset IDs from system_state
        known_asset_ids = []
        for entity_id in system_state.keys():
            if not (entity_id.startswith("INJ-") or entity_id.startswith("SCEN-")):
                if isinstance(system_state[entity_id], dict):
                    entity_type = system_state[entity_id].get("entity_type", "").lower()
                    if entity_type in ["server", "application", "database", "service", "asset"] or \
                       entity_id.startswith(("SRV-", "APP-", "DB-", "SVC-")):
                        known_asset_ids.append(entity_id)
        
        for asset_id in affected_assets:
            # ID-FIRST: Check if asset_id exists
            if asset_id in known_asset_ids or asset_id in system_state:
                # ID is correct. Now check description (optional - only warning, not error)
                asset_data = system_state.get(asset_id, {})
                if isinstance(asset_data, dict):
                    asset_name = asset_data.get("name", "")
                    # Check if content mentions asset with different name (optional check)
                    content_lower = inject.content.lower()
                    asset_name_lower = asset_name.lower() if asset_name else ""
                    # This is just for logging - we don't fail on name mismatches
                    if asset_name_lower and asset_name_lower not in content_lower and asset_id.lower() not in content_lower:
                        # Name mismatch detected, but ID is valid - only warning
                        warnings.append(
                            f"Name mismatch for {asset_id}: Content may use different name than '{asset_name}', but ID is valid. Proceeding."
                        )
                    
                    # Pr√ºfe Status-Konsistenz
                    asset_status = asset_data.get("status", "unknown")
                    
                    # Warnung wenn Asset bereits offline/compromised ist und als aktiv behandelt wird
                    if asset_status in ["offline", "compromised", "encrypted"]:
                        # Pr√ºfe ob Inject versucht, auf diesem Asset zu agieren
                        if any(keyword in content_lower for keyword in ["attack", "access", "lateral", "move"]):
                            warnings.append(
                                f"Asset '{asset_id}' ist bereits {asset_status}, aber Inject behandelt es als aktiv. "
                                "Pr√ºfe ob dies logisch ist."
                            )
            else:
                # Asset ID does not exist - THIS IS AN ERROR
                errors.append(
                    f"Unknown Asset ID: {asset_id}. "
                    f"Verf√ºgbare Assets: {known_asset_ids[:10] if known_asset_ids else list(system_state.keys())[:10]}"
                )
        
        # Pr√ºfe Asset-Name-Konsistenz mit vorherigen Injects
        if previous_injects:
            asset_names_used = set()
            for prev_inj in previous_injects[-3:]:  # Letzte 3 Injects
                asset_names_used.update(prev_inj.technical_metadata.affected_assets or [])
            
            # Warnung wenn komplett neue Assets ohne Kontext eingef√ºhrt werden
            new_assets = set(affected_assets) - asset_names_used
            if new_assets and len(asset_names_used) > 0:
                warnings.append(
                    f"Neue Assets ohne vorherigen Kontext eingef√ºhrt: {new_assets}. "
                    "Pr√ºfe ob dies logisch ist."
                )
        
        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings
        }
    
    def _validate_temporal_consistency(
        self,
        inject: Inject,
        previous_injects: List[Inject]
    ) -> Dict[str, Any]:
        """
        Validiert temporale Konsistenz (Zeitstempel, Sequenz).
        
        Returns:
            Dict mit "valid" (bool), "errors" (List[str]), "warnings" (List[str])
        """
        errors = []
        warnings = []
        
        if not previous_injects:
            return {"valid": True, "errors": errors, "warnings": warnings}
        
        # Parse Zeitstempel
        def parse_time_offset(offset: str) -> int:
            """Konvertiert T+HH:MM zu Minuten seit Start."""
            try:
                match = offset.replace("T+", "").split(":")
                hours = int(match[0])
                minutes = int(match[1])
                return hours * 60 + minutes
            except:
                return 0
        
        current_time = parse_time_offset(inject.time_offset)
        
        # Pr√ºfe ob Zeitstempel zur√ºckgeht
        for prev_inj in previous_injects:
            prev_time = parse_time_offset(prev_inj.time_offset)
            if current_time < prev_time:
                errors.append(
                    f"Temporale Inkonsistenz: Inject {inject.inject_id} hat Zeitstempel {inject.time_offset}, "
                    f"aber vorheriger Inject {prev_inj.inject_id} hat {prev_inj.time_offset} (sp√§ter). "
                    "Zeitstempel m√ºssen chronologisch sein."
                )
                return {"valid": False, "errors": errors, "warnings": warnings}
        
        # Warnung wenn Zeitstempel sehr weit in der Zukunft springt
        if previous_injects:
            last_time = parse_time_offset(previous_injects[-1].time_offset)
            time_diff = current_time - last_time
            if time_diff > 120:  # Mehr als 2 Stunden Sprung
                warnings.append(
                    f"Gro√üer Zeitsprung: {time_diff} Minuten seit letztem Inject. "
                    "Pr√ºfe ob dies realistisch ist."
                )
        
        return {"valid": True, "errors": errors, "warnings": warnings}
    
    def _check_regulatory_compliance(self, inject: Inject, current_phase: CrisisPhase) -> Dict[str, Any]:
        """
        Generische Regulatorik-Pr√ºfung (Business Continuity, Incident Response).
        
        Fokus auf Architektur-Funktionalit√§t. Regulatorische Anforderungen sind phasenabh√§ngig:
        - Fr√ºhe Phasen (NORMAL_OPERATION, SUSPICIOUS_ACTIVITY): Incident Response wichtig
        - Mittlere Phasen (INITIAL_INCIDENT, ESCALATION_CRISIS): Response + Business Continuity
        - Sp√§te Phasen (CONTAINMENT, RECOVERY): Business Continuity + Recovery Plan
        """
        checklist = {
            "risk_management_framework_tested": False,
            "business_continuity_policy_tested": False,
            "response_plan_tested": False,
            "recovery_plan_tested": False,
            "critical_functions_covered": False,
            "realistic_scenario": False,
            "documentation_adequate": False
        }
        
        issues = []
        warnings = []
        
        # Pr√ºfe Content auf regulatorische Aspekte (generisch, keine spezifische Regulatorik)
        content_lower = inject.content.lower()
        
        # 1. Risk Management Framework Testing (optional, nicht kritisch)
        if any(keyword in content_lower for keyword in ["risk assessment", "risk management", "vulnerability", "threat"]):
            checklist["risk_management_framework_tested"] = True
        
        # 2. Business Continuity Policy Testing (nur f√ºr sp√§te Phasen erw√ºnscht)
        if any(keyword in content_lower for keyword in ["business continuity", "continuity plan", "operational resilience", "service disruption", "backup"]):
            checklist["business_continuity_policy_tested"] = True
        
        # 3. Response Plan Testing (wichtig f√ºr fr√ºhe/mittlere Phasen)
        if any(keyword in content_lower for keyword in ["incident response", "response plan", "soc", "security operations", "alert", "detection", "siem"]):
            checklist["response_plan_tested"] = True
        
        # 4. Recovery Plan Testing (nur f√ºr RECOVERY-Phase erw√ºnscht)
        if any(keyword in content_lower for keyword in ["recovery", "restore", "backup", "restoration", "remediation"]):
            checklist["recovery_plan_tested"] = True
        
        # 5. Critical Functions Covered (optional, generisch)
        if inject.business_impact or any(keyword in content_lower for keyword in ["critical", "essential", "core", "service"]):
            checklist["critical_functions_covered"] = True
        
        # 6. Realistic Scenario (immer wichtig)
        if inject.technical_metadata.mitre_id and len(inject.technical_metadata.affected_assets) > 0:
            checklist["realistic_scenario"] = True
        else:
            issues.append("Inject ben√∂tigt technische Details (MITRE ID, Assets)")
        
        # 7. Documentation Adequate (immer wichtig)
        if len(inject.content) > 50 and inject.technical_metadata.mitre_id:
            checklist["documentation_adequate"] = True
        else:
            issues.append("Inject-Dokumentation sollte detaillierter sein (mindestens 50 Zeichen)")
        
        # PHASENABH√ÑNGIGE Compliance-Bewertung
        # Fr√ºhe Phasen: Response Plan wichtig, Rest optional
        # Sp√§te Phasen: Business Continuity + Recovery wichtig
        
        if current_phase in [CrisisPhase.NORMAL_OPERATION, CrisisPhase.SUSPICIOUS_ACTIVITY]:
            # Fr√ºhe Phasen: Response Plan sollte erw√§hnt werden, Rest optional
            phase_requirements_met = checklist["response_plan_tested"] or checklist["risk_management_framework_tested"]
        elif current_phase in [CrisisPhase.INITIAL_INCIDENT, CrisisPhase.ESCALATION_CRISIS]:
            # Mittlere Phasen: Response Plan wichtig, Business Continuity optional
            phase_requirements_met = checklist["response_plan_tested"]
        elif current_phase == CrisisPhase.CONTAINMENT:
            # Containment: Business Continuity wichtig
            phase_requirements_met = checklist["business_continuity_policy_tested"] or checklist["response_plan_tested"]
        elif current_phase == CrisisPhase.RECOVERY:
            # Recovery: Recovery Plan wichtig
            phase_requirements_met = checklist["recovery_plan_tested"] or checklist["business_continuity_policy_tested"]
        else:
            # Fallback: Mindestens eine Komponente
            phase_requirements_met = any([
                checklist["risk_management_framework_tested"],
                checklist["response_plan_tested"],
                checklist["business_continuity_policy_tested"],
                checklist["recovery_plan_tested"]
            ])
        
        # Basis-Anforderungen (immer wichtig)
        has_basic_requirements = (
            checklist["realistic_scenario"] and 
            checklist["documentation_adequate"]
        )
        
        # Compliance ist erf√ºllt wenn:
        # 1. Phasenabh√§ngige Anforderungen erf√ºllt ODER mindestens eine Komponente getestet
        # 2. Basis-Anforderungen erf√ºllt
        # 3. Keine kritischen Issues
        compliance_status = (
            (phase_requirements_met or any([
                checklist["risk_management_framework_tested"],
                checklist["response_plan_tested"],
                checklist["business_continuity_policy_tested"],
                checklist["recovery_plan_tested"]
            ]))
            and has_basic_requirements 
            and len(issues) == 0
        )
        
        return {
            "compliance_status": compliance_status,
            "checklist_results": checklist,
            "issues": issues,
            "warnings": warnings
        }
    
    def _llm_validate(
        self,
        inject: Inject,
        previous_injects: List[Inject],
        current_phase: CrisisPhase,
        system_state: Dict[str, Any],
        formatted_system_state_str: Optional[str] = None,
        compliance_results: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """LLM-basierte Validierung mit variablen Compliance-Standards."""
        
        # Generische Regulatorik-Check (vor LLM-Call)
        regulatory_check = self._check_regulatory_compliance(inject, current_phase)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Du bist ein erfahrener Security- und Krisenmanagement-Experte.
Deine Aufgabe ist es, Injects f√ºr Krisenszenarien STRENG zu validieren.

WICHTIG: Du bist der QUALIT√ÑTSGARANT des Systems. Sei PR√ÑZISE und STRENG.

VALIDIERUNGSKRITERIEN:

1. LOGISCHE KONSISTENZ (KRITISCH):
   - Widerspricht der Inject vorherigen Injects?
   - Ist die Sequenz logisch und kausal nachvollziehbar?
   - Ist der Content konsistent mit der Phase?
   
   ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è KRITISCH - ASSET-NAMEN (DIESE REGEL IST ABSOLUT VERBINDLICH):
   
   ‚ùå‚ùå‚ùå FEHLER: Es ist KEIN FEHLER, wenn ein Asset sowohl mit ID als auch mit Namen bezeichnet wird!
   
   ‚úÖ‚úÖ‚úÖ ERLAUBT (diese sind IMMER OK, niemals als Fehler melden):
   - "SRV-001" ‚Üí OK
   - "DC-01" ‚Üí OK (wenn SRV-001 = DC-01)
   - "SRV-001 (DC-01)" ‚Üí OK (beide zusammen)
   - "Domain Controller SRV-001" ‚Üí OK (Name + ID)
   - "Application Server APP-SRV-01 (SRV-002)" ‚Üí OK (verschiedene Namen f√ºr dasselbe Asset)
   - "Payment Processing System" ‚Üí OK (wenn APP-001 = Payment Processing System)
   - "APP-001" ‚Üí OK
   - "Payment Processing System (APP-001)" ‚Üí OK
   - "APP-001 wird als Payment Processing System bezeichnet" ‚Üí OK (beide Namen verwendet)
   
   ‚ùå NUR DIESE SIND ECHTE FEHLER:
   - Asset-ID existiert nicht (z.B. verwendet "SRV-003" aber nur SRV-001, SRV-002 existieren)
   - Asset ist offline, wird aber als aktiv verwendet (z.B. "SRV-001 ist offline" in Inject 1, aber "Lateral Movement von SRV-001" in Inject 2)
   
   ‚ö†Ô∏è WICHTIG: Wenn ein Asset sowohl mit ID als auch mit Namen bezeichnet wird, ist das IMMER ERLAUBT. 
   Melde dies NIEMALS als "Asset-Name-Inkonsistenz" Fehler!

2. CAUSAL VALIDITY (KRITISCH):
   - Passt die MITRE ATT&CK Technik zur aktuellen Phase?
   - Ist die Sequenz technisch m√∂glich?
   
   ‚ö†Ô∏è WICHTIG - KAUSALE LOGIK:
   - Phasen-√úberg√§nge zeigen bereits die kausale Logik! Wenn wir von SUSPICIOUS_ACTIVITY zu INITIAL_INCIDENT gehen, ist das bereits ein kausaler Vorg√§nger
   - Du musst NICHT erwarten, dass jeder Schritt explizit in vorherigen Injects erw√§hnt wird
   - Pr√ºfe nur, ob die Sequenz technisch m√∂glich ist, nicht ob sie explizit erw√§hnt wurde
   
   WICHTIG: Sei nicht zu streng! Viele MITRE-Techniken k√∂nnen in mehreren Phasen vorkommen.
   
   BEISPIEL F√úR INVALIDIT√ÑT (nur wirklich unm√∂gliche Sequenzen):
   - Phase: NORMAL_OPERATION, MITRE: T1041 (Exfiltration) ‚Üí FEHLER: Exfiltration vor Initial Access unm√∂glich!
   - Phase: NORMAL_OPERATION, MITRE: T1486 (Data Encrypted for Impact) ‚Üí FEHLER: Impact vor Execution unm√∂glich!
   
   BEISPIEL F√úR VALIDIT√ÑT (diese sind OK):
   - Phase: SUSPICIOUS_ACTIVITY, MITRE: T1595 (Active Scanning) ‚Üí OK: Scanning kann in verschiedenen Phasen vorkommen
   - Phase: INITIAL_INCIDENT, MITRE: T1546.014 (Event Triggered Execution) ‚Üí OK: Kann nach SUSPICIOUS_ACTIVITY vorkommen (Phasen-√úbergang zeigt Logik)
   - Phase: INITIAL_INCIDENT, MITRE: T1480 (Execution Guardrails) ‚Üí OK: Kann in verschiedenen Phasen vorkommen, auch wenn nicht explizit erw√§hnt

3. REGULATORISCHE ASPEKTE (optional, nicht blockierend):
   - Incident Response Plan Testing
   - Business Continuity Plan Testing
   - Recovery Plan Testing
   - Coverage of critical functions
   - Realistic scenario testing
   - Documentation adequate

VALIDIERUNGSREGELN:
- Sei STRENG aber FAIR: Bei echten Verst√∂√üen ‚Üí FEHLER melden, bei Unsicherheiten ‚Üí Warnung
- Jeder Fehler MUSS eine klare, spezifische Begr√ºndung haben
- Warnungen f√ºr potenzielle Probleme, Fehler f√ºr klare Verst√∂√üe
- Pr√ºfe ALLE Aspekte: Logik, Kausalit√§t, State, Temporalit√§t
- ASSET-NAMEN: Erlaube sowohl IDs als auch Namen (siehe oben)
- KAUSALE LOGIK: Phasen-√úberg√§nge zeigen bereits die Logik (siehe oben)

ANTWORT-FORMAT (STRICT JSON):
{{
    "logical_consistency": true/false,
    "regulatory_compliance": true/false,
    "causal_validity": true/false,
    "errors": ["Spezifischer Fehler 1 mit Begr√ºndung", "Spezifischer Fehler 2 mit Begr√ºndung"],
    "warnings": ["Potenzielle Warnung 1", "Potenzielle Warnung 2"]
}}

FEHLER-MUSTER (wenn diese auftreten ‚Üí FEHLER):
- Asset existiert nicht im Systemzustand (z.B. verwendet "SRV-003" aber nur SRV-001, SRV-002 existieren)
- Asset ist offline, wird aber als aktiv behandelt (z.B. "SRV-001 ist offline" in Inject 1, aber "Lateral Movement von SRV-001" in Inject 2)
- MITRE-Technik passt nicht zur Phase (nur wirklich unm√∂gliche Sequenzen, siehe oben)
- Temporale Inkonsistenz (Zeitstempel geht zur√ºck)
- Asset-ID ist falsch (z.B. verwendet "SRV-003" statt "SRV-001")

WARNUNG-MUSTER (wenn diese auftreten ‚Üí WARNUNG, nicht Fehler):
- Gro√üer Zeitsprung ohne Erkl√§rung
- Neue Assets ohne Kontext
- Ungew√∂hnliche aber m√∂gliche Sequenz
- MITRE-Technik passt m√∂glicherweise nicht perfekt zur Phase (aber technisch m√∂glich)
- Kausale Sequenz k√∂nnte besser erkl√§rt werden (aber Phasen-√úbergang zeigt bereits Logik)

‚ùå‚ùå‚ùå ABSOLUT VERBOTEN - MELDE DIESE NIEMALS ALS FEHLER:
- "Asset-Name-Inkonsistenz" wenn ein Asset sowohl mit ID als auch mit Namen bezeichnet wird
- "Asset-Name-Inkonsistenz" wenn verschiedene Namen f√ºr dasselbe Asset verwendet werden (z.B. "SRV-001" und "DC-01")
- "Asset-Name-Inkonsistenz" wenn "Payment Processing System" und "APP-001" f√ºr dasselbe Asset verwendet werden
- "Asset-Name-Inkonsistenz" wenn "Application Server APP-SRV-01" und "SRV-002" f√ºr dasselbe Asset verwendet werden

‚ö†Ô∏è Wenn du denkst, dass verschiedene Namen f√ºr dasselbe Asset verwendet werden, ist das ERLAUBT. 
Melde es NIEMALS als Fehler, h√∂chstens als Warnung wenn es wirklich verwirrend ist!"""),
            
            ("human", """Validiere folgenden Inject STRENG:

Inject:
{inject}

Aktuelle Phase: {current_phase}
Vorherige Phase: {previous_phase}

Vorherige Injects (f√ºr Konsistenz-Pr√ºfung):
{previous_injects}

Systemzustand (verf√ºgbare Assets und deren Status):
{system_state}

MITRE ATT&CK Technik: {mitre_id}
Regulatorische Checkliste (automatisch gepr√ºft):
{regulatory_checklist_results}

SYMBOLISCHE VALIDIERUNG (bereits gepr√ºft):
- FSM-√úbergang: ‚úì OK
- State-Consistency: ‚úì OK
- Temporale Konsistenz: ‚úì OK

LLM-VALIDIERUNG (deine Aufgabe):
Pr√ºfe jetzt:
1. LOGISCHE KONSISTENZ: Widerspricht der Inject der Historie oder dem Systemzustand?
2. CAUSAL VALIDITY: Passt MITRE {mitre_id} zur Phase {current_phase} und zur Sequenz?
3. REGULATORISCHE ASPEKTE: Erf√ºllt der Inject die grundlegenden Anforderungen? (optional, nicht blockierend)

Antworte STRICT JSON (nur JSON, keine zus√§tzlichen Erkl√§rungen au√üerhalb des JSON).""")
        ])
        
        # Formatierung
        previous_injects_str = self._format_previous_injects(previous_injects)
        system_state_str = formatted_system_state_str or self._format_system_state(system_state)
        inject_str = self._format_inject(inject)
        
        # Bestimme vorherige Phase
        previous_phase = previous_injects[-1].phase.value if previous_injects else current_phase.value
        
        # Formatiere Regulatorik-Checkliste f√ºr Prompt
        regulatory_checklist_str = "\n".join([
            f"- {key.replace('_', ' ').title()}: {'‚úì' if value else '‚úó'}"
            for key, value in regulatory_check["checklist_results"].items()
        ])
        
        chain = prompt | self.llm
        
        # Retry-Logik f√ºr LLM-Call
        from utils.retry_handler import safe_llm_call
        
        try:
            def _invoke_chain():
                return chain.invoke({
                    "inject": inject_str,
                    "current_phase": current_phase.value,
                    "previous_phase": previous_phase,
                    "previous_injects": previous_injects_str,
                    "system_state": system_state_str,
                    "mitre_id": inject.technical_metadata.mitre_id or "Unknown",
                    "regulatory_checklist_results": regulatory_checklist_str
                })
            
            response = safe_llm_call(
                _invoke_chain,
                max_attempts=3,
                default_return=None
            )
            
            if response is None:
                # Fallback: Verwende Regulatorik-Check Ergebnisse
                return {
                    "logical_consistency": True,
                    "regulatory_compliance": regulatory_check["compliance_status"],
                    "causal_validity": True,
                    "errors": regulatory_check["issues"],
                    "warnings": regulatory_check["warnings"] + ["Validierung konnte nicht durchgef√ºhrt werden - LLM-Call fehlgeschlagen"],
                    "_raw_llm_output": "LLM-Call fehlgeschlagen (response is None)"
                }
            
            # Parse JSON
            import json
            import re
            
            content = response.content
            raw_llm_output = content  # Speichere RAW Output f√ºr Audit-Log
            
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            
            if json_match:
                validation = json.loads(json_match.group())
                
                # Extrahiere und validiere Felder
                logical_consistency = validation.get("logical_consistency", True)
                causal_validity = validation.get("causal_validity", True)
                llm_regulatory_compliance = validation.get("regulatory_compliance", True)
                
                # Kombiniere LLM-Validierung mit Regulatorik-Check
                combined_errors = validation.get("errors", []) or []
                combined_warnings = validation.get("warnings", []) or []
                
                # POST-PROCESSING: Konvertiere falsche "Asset-Name-Inkonsistenz" Fehler zu Warnungen
                # Der LLM meldet manchmal f√§lschlicherweise Asset-Name-Inkonsistenzen als Fehler,
                # obwohl verschiedene Namen f√ºr dasselbe Asset erlaubt sind
                asset_name_error_patterns = [
                    "Asset-Name-Inkonsistenz",
                    "wird sowohl als",
                    "als auch als",
                    "bezeichnet",
                    "sollte aber",
                    "nicht als"
                ]
                
                # Pr√ºfe ob es sich um eine Asset-Name-Inkonsistenz handelt
                real_errors = []
                for error in combined_errors:
                    is_asset_name_error = any(pattern.lower() in error.lower() for pattern in asset_name_error_patterns)
                    # Pr√ºfe ob es ein echter Fehler ist (falsche Asset-ID oder offline Asset)
                    is_real_error = (
                        "existiert nicht" in error.lower() or
                        "offline" in error.lower() or
                        "nicht im Systemzustand" in error.lower() or
                        "Asset-ID ist falsch" in error.lower()
                    )
                    
                    if is_asset_name_error and not is_real_error:
                        # Konvertiere zu Warnung
                        combined_warnings.append(f"Asset-Namensvariation: {error} (erlaubt, nur zur Info)")
                    else:
                        real_errors.append(error)
                
                combined_errors = real_errors
                
                # Regulatorik-Issues sind nur Warnungen, keine Fehler (nicht blockierend)
                # Nur kritische Issues (z.B. fehlende technische Details) sind Fehler
                critical_regulatory_issues = [issue for issue in regulatory_check["issues"] 
                                             if "technische Details" in issue or "Dokumentation" in issue]
                combined_errors.extend(critical_regulatory_issues)
                combined_warnings.extend(regulatory_check["warnings"])
                # Alle anderen Regulatorik-Issues sind nur Warnungen
                non_critical_regulatory_issues = [issue for issue in regulatory_check["issues"] 
                                                 if issue not in critical_regulatory_issues]
                combined_warnings.extend(non_critical_regulatory_issues)
                
                # Regulatorik Compliance: Muss sowohl LLM als auch Checkliste erf√ºllen
                # ABER: Nicht blockierend - nur Warnung
                checklist_regulatory_compliance = regulatory_check["compliance_status"]
                final_regulatory_compliance = llm_regulatory_compliance and checklist_regulatory_compliance
                
                # Stelle sicher, dass bei False-Werten immer Fehler vorhanden sind
                # ABER: Regulatorik-Compliance ist weniger kritisch - nur Warnung wenn nicht erf√ºllt
                if not logical_consistency and not combined_errors:
                    combined_errors.append("LLM meldet fehlende logische Konsistenz ohne spezifische Fehler.")
                if not causal_validity and not combined_errors:
                    # Causal Validity: Pr√ºfe ob es wirklich unm√∂glich ist oder nur ungew√∂hnlich
                    # Wenn nur ungew√∂hnlich ‚Üí Warnung statt Fehler
                    combined_warnings.append("MITRE-Technik passt m√∂glicherweise nicht perfekt zur Phase (pr√ºfe ob technisch m√∂glich)")
                # Regulatorik-Compliance: Warnung statt Fehler (nicht blockierend)
                if not final_regulatory_compliance:
                    if not any("Regulatorik" in w or "Compliance" in w for w in combined_warnings):
                        combined_warnings.append("Regulatorische Aspekte k√∂nnten besser abgedeckt sein (optional)")
                
                result = {
                    "logical_consistency": logical_consistency,
                    "dora_compliance": final_regulatory_compliance,  # F√ºr R√ºckw√§rtskompatibilit√§t behalten
                    "regulatory_compliance": final_regulatory_compliance,
                    "causal_validity": causal_validity,
                    "errors": combined_errors,
                    "warnings": combined_warnings,
                    "regulatory_checklist": regulatory_check["checklist_results"],
                    "_raw_llm_output": raw_llm_output  # F√ºr Audit-Log - RAW Output vor JSON-Parsing
                }
                return result
            else:
                # Fallback: Verwende Regulatorik-Check Ergebnisse
                return {
                    "logical_consistency": True,
                    "regulatory_compliance": regulatory_check["compliance_status"],
                    "causal_validity": True,
                    "errors": regulatory_check["issues"],
                    "warnings": regulatory_check["warnings"] + ["Validierung konnte nicht vollst√§ndig durchgef√ºhrt werden"],
                    "_raw_llm_output": content if 'content' in locals() else "Kein JSON-Match gefunden"
                }
                
        except Exception as e:
            # Fallback bei Fehler: Verwende Regulatorik-Check Ergebnisse
            return {
                "logical_consistency": True,
                "regulatory_compliance": regulatory_check["compliance_status"],
                "causal_validity": True,
                "errors": regulatory_check["issues"],
                "warnings": regulatory_check["warnings"] + [f"Validierungsfehler: {e}"],
                "_raw_llm_output": f"Exception: {str(e)}"
            }
    
    def _format_inject(self, inject: Inject) -> str:
        """Formatiert einen Inject f√ºr den Prompt."""
        lines = [
            f"Inject ID: {inject.inject_id}",
            f"Time Offset: {inject.time_offset}",
            f"Phase: {inject.phase.value}",
            f"Source: {inject.source}",
            f"Target: {inject.target}",
            f"Modality: {inject.modality.value}",
            f"Content: {inject.content}",
            f"MITRE ID: {inject.technical_metadata.mitre_id}",
            f"Affected Assets: {', '.join(inject.technical_metadata.affected_assets)}"
        ]
        return "\n".join(lines)
    
    def _format_previous_injects(self, previous_injects: List[Inject]) -> str:
        """Formatiert vorherige Injects."""
        if not previous_injects:
            return "Keine vorherigen Injects"
        
        lines = []
        for inj in previous_injects[-5:]:  # Letzte 5
            lines.append(f"- {inj.inject_id} ({inj.time_offset}): {inj.content[:60]}...")
        
        return "\n".join(lines)
    
    def _format_system_state(self, system_state: Dict[str, Any]) -> str:
        """
        Formatiert den Systemzustand mit expliziter Asset-Liste.
        
        WICHTIG: Filtert nur echte Assets, keine INJ-* oder SCEN-* IDs.
        """
        if not system_state or not isinstance(system_state, dict):
            return "Keine Systemzustand-Informationen verf√ºgbar. Verwende Standard-Assets: SRV-001, SRV-002"
        
        # Filtere echte Assets heraus (keine INJ-*, SCEN-* IDs)
        valid_assets = {}
        for entity_id, entity_data in system_state.items():
            # √úberspringe Inject-IDs und Szenario-IDs
            if entity_id.startswith("INJ-") or entity_id.startswith("SCEN-"):
                continue
            
            # Nur echte Assets
            if isinstance(entity_data, dict):
                entity_type = entity_data.get("entity_type", "").lower()
                if entity_type in ["server", "application", "database", "service", "asset"] or \
                   entity_id.startswith(("SRV-", "APP-", "DB-", "SVC-")):
                    valid_assets[entity_id] = entity_data
        
        if not valid_assets:
            return "Keine Assets im Systemzustand verf√ºgbar. Verwende Standard-Assets: SRV-001, SRV-002"
        
        lines = []
        asset_list = []
        for entity_id, entity_data in valid_assets.items():
            status = entity_data.get("status", "unknown")
            name = entity_data.get("name", entity_id)
            entity_type = entity_data.get("entity_type", "Asset")
            lines.append(f"- {name} ({entity_id}, {entity_type}): {status}")
            asset_list.append(entity_id)
        
        # WICHTIG: Explizite Liste der verf√ºgbaren Asset-IDs
        result = "\n".join(lines) if lines else "Alle Systeme im Normalbetrieb"
        result += f"\n\n‚ö†Ô∏è KRITISCH - VERF√úGBARE ASSET-IDs (NUR DIESE VERWENDEN!): {', '.join(asset_list)}"
        result += f"\n‚ùå VERBOTEN: Erstelle KEINE neuen Assets! Verwende NUR die oben genannten Asset-IDs!"
        
        return result
    
    def _log_critic_decision(
        self,
        inject_id: str,
        inject: Inject,
        system_state: Dict[str, Any],
        previous_injects: List[Inject],
        current_phase: CrisisPhase,
        llm_validation: Dict[str, Any],
        final_result: Dict[str, Any],
        formatted_system_state_str: Optional[str] = None
    ) -> None:
        """
        Loggt die vollst√§ndige Critic-Entscheidung f√ºr Deep Truth Debugging.
        
        Erstellt einen detaillierten Audit-Eintrag in CRITIC_AUDIT_LOG.md.
        """
        # Verwende absoluten Pfad vom Workspace-Root
        workspace_root = Path(__file__).parent.parent
        log_file = workspace_root / "CRITIC_AUDIT_LOG.md"
        
        # Extrahiere Asset-IDs aus system_state
        active_assets = []
        for entity_id, entity_data in system_state.items():
            if entity_id.startswith(("INJ-", "SCEN-")):
                continue
            if isinstance(entity_data, dict):
                entity_type = entity_data.get("entity_type", "").lower()
                if entity_type in ["server", "application", "database", "service", "asset"] or \
                   entity_id.startswith(("SRV-", "APP-", "DB-", "SVC-")):
                    active_assets.append(entity_id)
        
        # Formatiere System-State-String (wie er an LLM gesendet wurde)
        if formatted_system_state_str is None:
            formatted_system_state_str = self._format_system_state(system_state)
        
        # Formatiere vorherige Injects
        previous_injects_json = []
        for prev_inj in previous_injects:
            previous_injects_json.append({
                "inject_id": prev_inj.inject_id,
                "time_offset": prev_inj.time_offset,
                "phase": prev_inj.phase.value,
                "content": prev_inj.content,
                "affected_assets": prev_inj.technical_metadata.affected_assets,
                "mitre_id": prev_inj.technical_metadata.mitre_id
            })
        
        # Vollst√§ndiger Inject JSON
        inject_json = {
            "inject_id": inject.inject_id,
            "time_offset": inject.time_offset,
            "phase": inject.phase.value,
            "source": inject.source,
            "target": inject.target,
            "modality": inject.modality.value,
            "content": inject.content,
            "technical_metadata": {
                "mitre_id": inject.technical_metadata.mitre_id,
                "affected_assets": inject.technical_metadata.affected_assets,
                "ioc_hash": inject.technical_metadata.ioc_hash,
                "ioc_ip": inject.technical_metadata.ioc_ip,
                "ioc_domain": inject.technical_metadata.ioc_domain,
                "severity": inject.technical_metadata.severity
            },
            "dora_compliance_tag": inject.dora_compliance_tag,
            "business_impact": inject.business_impact
        }
        
        # Raw LLM Output
        raw_llm_output = llm_validation.get("_raw_llm_output", "Nicht verf√ºgbar")
        
        # Entscheidung
        decision = "‚úÖ VALID" if final_result["is_valid"] else "‚ùå INVALID"
        
        # Erstelle Markdown-Eintrag
        timestamp = datetime.now().isoformat()
        
        # Hole FSM-Regeln f√ºr aktuelle Phase
        try:
            from workflows.fsm import CrisisFSM
            allowed_transitions = CrisisFSM.get_next_phases(current_phase)
            allowed_transitions_str = [p.value for p in allowed_transitions]
        except:
            allowed_transitions_str = ["N/A"]
        
        markdown_entry = f"""## üîç Audit Entry: {inject_id}
**Timestamp:** {timestamp}

### 1. The Ground Truth (What was in the DB?)
*Crucial: Dump the exact JSON inputs the Critic received.*

- **Active Assets in State:** `{json.dumps(active_assets, indent=2, ensure_ascii=False, cls=DateTimeEncoder)}`
- **Current Phase:** `{current_phase.value}`
- **System State (Full Raw):**
```json
{json.dumps(system_state, indent=2, ensure_ascii=False, cls=DateTimeEncoder)}
```
- **System State (Formatted - wie an LLM gesendet):**
```
{formatted_system_state_str}
```
- **Previous Injects (Full History):**
```json
{json.dumps(previous_injects_json, indent=2, ensure_ascii=False, cls=DateTimeEncoder)}
```
- **Defined Rules:**
  - **FSM Transition Rules:** Valid transitions from `{current_phase.value}` ‚Üí `{allowed_transitions_str}`
  - **State Consistency:** Assets must exist in system_state (checked against: `{active_assets}`)
  - **Temporal Consistency:** Time offsets must be chronological
  - **Logical Consistency:** No contradictions with previous injects
  - **Causal Validity:** MITRE techniques must be technically possible (only truly impossible sequences block)

### 2. The Generator's Draft
```json
{json.dumps(inject_json, indent=2, ensure_ascii=False, cls=DateTimeEncoder)}
```

### 3. The Critic's Reasoning (Raw LLM Output)
*Crucial: What did the LLM actually say before parsing?*

```
{raw_llm_output}
```

### 4. The Verdict
- **Decision:** {decision}
- **Detected Errors:** {json.dumps(final_result.get("errors", []), indent=2, ensure_ascii=False, cls=DateTimeEncoder)}
- **Warnings:** {json.dumps(final_result.get("warnings", []), indent=2, ensure_ascii=False, cls=DateTimeEncoder)}
- **Validation Details:**
  - Pydantic Valid: `{final_result.get("pydantic_valid", "N/A")}`
  - FSM Valid: `{final_result.get("fsm_valid", "N/A")}`
  - State Valid: `{final_result.get("state_valid", "N/A")}`
  - Temporal Valid: `{final_result.get("temporal_valid", "N/A")}`
  - Logical Consistency: `{final_result.get("logical_consistency", "N/A")}`
  - Causal Validity: `{final_result.get("causal_validity", "N/A")}`
  - Causal Blocking: `{final_result.get("causal_blocking", "N/A")}`

***

"""
        
        # Append to log file (mit Header falls Datei neu)
        try:
            file_exists = log_file.exists()
            with open(log_file, "a", encoding="utf-8") as f:
                if not file_exists:
                    # Header beim ersten Eintrag
                    f.write("# üîç Critic Agent Deep Truth Audit Log\n\n")
                    f.write("Diese Datei enth√§lt vollst√§ndige Audit-Trails f√ºr alle Critic-Validierungen.\n")
                    f.write("Jeder Eintrag zeigt die exakten Inputs, den Generator-Draft, die LLM-Antwort und die finale Entscheidung.\n\n")
                    f.write("---\n\n")
                f.write(markdown_entry)
            print(f"üìù [Critic] Audit-Log geschrieben: {log_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è  [Critic] Fehler beim Schreiben des Audit-Logs: {e}")

